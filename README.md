# whisperlocal ‚Äî Servidor FastAPI modular para Whisper

Proyecto modular que expone un endpoint REST para transcribir audios usando **OpenAI Whisper** (modelo local).

---

## üìÅ Estructura del proyecto

* `main.py`: Punto de entrada de la aplicaci√≥n, configura FastAPI y la startup.
* `config.py`: Variables de configuraci√≥n centralizadas (modelo, puerto, idioma, etc.).
* `models.py`: Modelos Pydantic para validaci√≥n de entrada/salida.
* `services.py`: L√≥gica de negocio (`WhisperService`) separada de las rutas.
* `routes.py`: Definici√≥n de endpoints de la API.
* `GPU.md`: Gu√≠a opcional para configurar Whisper con GPU (CUDA).

---

## ‚úÖ Ventajas de esta estructura modular

* Separaci√≥n clara de responsabilidades.
* C√≥digo m√°s f√°cil de mantener y escalar.
* Pruebas unitarias m√°s simples.
* Configuraci√≥n centralizada.
* Mejor legibilidad del c√≥digo.
* Posible reutilizaci√≥n de `WhisperService` en otros proyectos.

---

## üöÄ Requisitos (r√°pido)

Desde el entorno virtual del proyecto (`.venv`), instala:

```bash
pip install openai-whisper pydantic fastapi uvicorn
```

Si planeas usar GPU, revisa el archivo `GPU.md`.

---

## ‚öôÔ∏è Variables de entorno

Puedes personalizar el comportamiento del servidor mediante variables de entorno:

* `WHISPER_MODEL` ‚Äî Modelo a usar (`tiny`, `base`, `small`, `medium`, `large`).
  **Default:** `base`
* `WHISPER_DEVICE` ‚Äî Dispositivo (`cpu` o `cuda`).
  **Default:** `cpu`
* `DEFAULT_LANGUAGE` ‚Äî Idioma por defecto (c√≥digo tipo `es`, `en`, etc.).
  **Default:** `es`
* `HOST` ‚Äî Host para uvicorn.
  **Default:** `0.0.0.0`
* `PORT` ‚Äî Puerto HTTP del servidor.
  **Default:** `8000`
* `DEBUG` ‚Äî Modo debug (`True`/`False`).
  **Default:** `False`

### Ejemplo en Linux/Mac (bash)

```bash
export WHISPER_MODEL=base
export WHISPER_DEVICE=cpu
export DEFAULT_LANGUAGE=es
export HOST=0.0.0.0
export PORT=8000
export DEBUG=False
```

### Ejemplo en Windows (cmd.exe)

```cmd
set WHISPER_MODEL=base
set WHISPER_DEVICE=cpu
set DEFAULT_LANGUAGE=es
set HOST=0.0.0.0
set PORT=8000
set DEBUG=False
```

---

## üß† Elegir el modelo de Whisper seg√∫n tu PC

Whisper incluye varios tama√±os de modelo. La idea general:

* Mientras **m√°s peque√±o** es el modelo ‚Üí **menos recursos** consume y **m√°s r√°pido** es, pero puede ser **menos preciso**.
* Mientras **m√°s grande** es el modelo ‚Üí **m√°s RAM/VRAM** necesita y **es m√°s lento**, pero mejora la **calidad de la transcripci√≥n**.

### Modelos m√°s usados en `openai-whisper`

| Modelo   | Calidad aprox. | Velocidad      | RAM/VRAM recomendada | Uso recomendado                                      |
| -------- | -------------- | -------------- | -------------------- | ---------------------------------------------------- |
| `tiny`   | B√°sica         | üöÄ Muy alta    | ‚â• 2 GB               | PCs muy modestas, pruebas r√°pidas, audios cortos     |
| `base`   | Mejor que tiny | üöÄ Alta        | ‚â• 4 GB               | Buen punto de inicio en la mayor√≠a de PCs            |
| `small`  | Buena          | ‚öñÔ∏è Media       | ‚â• 6‚Äì8 GB             | Mejor calidad, si tu PC aguanta                      |
| `medium` | Muy buena      | üê¢ Lenta       | ‚â• 8‚Äì12 GB            | Equipos con buena CPU o GPU, proyectos m√°s exigentes |
| `large`  | Excelente      | üê¢üê¢ M√°s lenta | ‚â• 12‚Äì16 GB           | Servidores potentes / GPU dedicada, m√°xima calidad   |

> Tambi√©n existen variantes como `tiny.en`, `base.en`, `small.en`, `medium.en` optimizadas solo para ingl√©s.
> Para este proyecto en espa√±ol normalmente usaremos los modelos **sin** `.en`.

### Recomendaciones r√°pidas para tus compa√±eros

1. üíª **Port√°til b√°sico (4 GB RAM, sin GPU potente)**

   * Usa: `tiny` o `base`
   * Ejemplo:

     ```cmd
     set WHISPER_MODEL=base
     ```

2. üíª **PC de escritorio media (8 GB RAM, CPU decente)**

   * Usa: `base` o `small`
   * Ejemplo:

     ```cmd
     set WHISPER_MODEL=small
     ```

3. üñ•Ô∏è **PC/GPU potente (RTX, 8‚Äì12+ GB de VRAM)**

   * Usa: `small`, `medium` o incluso `large`
   * Ejemplo:

     ```cmd
     set WHISPER_MODEL=medium
     set WHISPER_DEVICE=cuda
     ```

---

## ‚ñ∂Ô∏è C√≥mo ejecutar el servidor

Puedes ejecutarlo de dos formas:

### Desde PyCharm

1. Abre el proyecto en PyCharm.
2. Aseg√∫rate de que el int√©rprete apunte a tu entorno virtual (si usas `.venv`).
3. Abre `main.py`.
4. Haz clic en el bot√≥n **Play (‚ñ∂Ô∏è)** para ejecutar.

### Desde la terminal

En la ra√≠z del proyecto:

```bash
python main.py
```

Por defecto, el servidor quedar√° disponible en:

```text
http://127.0.0.1:8000
```

> Si inicias con `HOST=0.0.0.0`, deber√°s usar la IP del servidor para acceder desde otros equipos de la red.

---

## üéØ Endpoint principal: `/api/transcribe`

* **M√©todo:** `POST`
* **URL:** `http://127.0.0.1:8000/api/transcribe`
* **Content-Type:** `application/json`

### Body (JSON)

* `file_path` (string, requerido) ‚Äî Ruta completa al archivo de audio **en el sistema de archivos del servidor**.
* `language` (string, opcional) ‚Äî C√≥digo de idioma (`es`, `en`, `fr`, etc.). Si no se env√≠a, se usa `DEFAULT_LANGUAGE`.

Ejemplo (Windows, JSON):

```json
{
  "file_path": "C:\\\\Users\\\\HALO\\\\Downloads\\\\IRIS OUT - Chainsaw Man - The Movie_ Reze Arc (Spanish Cover by Tricker).mp3",
  "language": "es"
}
```

> Nota: en JSON las barras invertidas (`\`) deben ir escapadas (`\\`).

### Respuesta exitosa (ejemplo)

```json
{
  "text": "Hola, este es el texto transcrito del audio."
}
```

---

## üìù Par√°metros

| Par√°metro   | Tipo   | Requerido | Descripci√≥n                            |
| ----------- | ------ | --------- | -------------------------------------- |
| `file_path` | string | ‚úÖ         | Ruta completa al archivo de audio      |
| `language`  | string | ‚ùå         | C√≥digo de idioma (por defecto: `"es"`) |

---

## üéµ Formatos de audio soportados

Whisper soporta m√∫ltiples formatos, entre ellos:

* MP3 (`.mp3`)
* WAV (`.wav`)
* M4A (`.m4a`)
* FLAC (`.flac`)
* OGG (`.ogg`)
* Y muchos m√°s‚Ä¶

---

## üåê Idiomas soportados

Whisper soporta un gran n√∫mero de idiomas. Algunos comunes:

* `es` ‚Äî Espa√±ol
* `en` ‚Äî Ingl√©s
* `fr` ‚Äî Franc√©s
* `de` ‚Äî Alem√°n
* `it` ‚Äî Italiano
* `pt` ‚Äî Portugu√©s
* `ja` ‚Äî Japon√©s
* `zh` ‚Äî Chino

(‚Ä¶y otros muchos c√≥digos est√°ndar ISO 639-1).

---

## üöÄ C√≥mo transcribir un audio (paso a paso)

1. Aseg√∫rate de que el servidor est√© ejecut√°ndose (`main.py` en marcha).
2. Verifica que el archivo de audio exista en la ruta indicada.
3. Env√≠a una petici√≥n `POST` al endpoint `/api/transcribe` con el JSON correcto.
4. Revisa la respuesta JSON: el campo `text` contiene la transcripci√≥n.

---

## üíª Ejemplos pr√°cticos de consumo

### Desde Python

```python
import requests

payload = {
    "file_path": r"C:\\Users\\HALO\\Desktop\\audio.mp3",
    "language": "es"
}

response = requests.post(
    "http://127.0.0.1:8000/api/transcribe",
    json=payload
)

data = response.json()
print("Texto transcrito:", data["text"])
```

### Desde cURL (Linux/Mac)

```bash
curl -X POST "http://127.0.0.1:8000/api/transcribe" \
     -H "Content-Type: application/json" \
     -d '{"file_path": "/ruta/completa/al/archivo.mp3", "language": "es"}'
```

### Desde cURL (Windows cmd)

```cmd
curl -X POST "http://127.0.0.1:8000/api/transcribe" ^
     -H "Content-Type: application/json" ^
     -d "{\"file_path\": \"C:\\\\Users\\\\HALO\\\\Desktop\\\\audio.mp3\", \"language\": \"es\"}"
```

---

## üõ†Ô∏è Depuraci√≥n de errores comunes

* **HTTP 422 Unprocessable Entity**
  El JSON enviado no coincide con el modelo esperado.

  * Aseg√∫rate de enviar `file_path` (y opcionalmente `language`) en el body.
  * Verifica que el `Content-Type` sea `application/json`.
  * Revisa comillas y comas en el JSON.

* **‚ÄúArchivo no encontrado‚Äù / errores de ruta**

  * Verifica que la ruta exista y sea accesible desde el servidor.
  * En Windows, revisa bien las barras invertidas y los permisos.

* **`FP16 is not supported on CPU`**

  * Mensaje informativo: cuando Whisper intenta usar fp16 en CPU.
  * No suele ser cr√≠tico: el modelo se ejecuta en fp32 autom√°ticamente.

* **Problemas de memoria (OOM)**

  * Prueba con un modelo m√°s peque√±o (`base` o `tiny`).
  * Cierra otros programas que consuman mucha RAM/VRAM.

---

## ‚ö° Uso de GPU (opcional)

Si quieres usar Whisper con GPU (por ejemplo, una RTX):

1. Instala PyTorch con soporte CUDA (consulta la gu√≠a oficial seg√∫n tu versi√≥n de CUDA).

2. Configura la variable de entorno:

   ```bash
   export WHISPER_DEVICE=cuda
   # o en Windows:
   # set WHISPER_DEVICE=cuda
   ```

3. Elige un modelo acorde a tu VRAM (`small`, `medium` o `large`).

4. Revisa el archivo `GPU.md` incluido en el proyecto para una gu√≠a paso a paso.

---

## üìö Archivos √∫tiles

* `main.py` ‚Äî Punto de entrada del servidor FastAPI.
* `config.py` ‚Äî Configuraci√≥n centralizada (modelo, device, idioma, puerto‚Ä¶).
* `models.py` ‚Äî Esquemas Pydantic para request/response.
* `services.py` ‚Äî L√≥gica principal de transcripci√≥n (`WhisperService`).
* `routes.py` ‚Äî Rutas y endpoints de la API.
* `GPU.md` ‚Äî Gu√≠a para habilitar GPU/CUDA.

---
 
 
